{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"name":"python","version":"3.10.12","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"},"kaggle":{"accelerator":"none","dataSources":[{"sourceId":10837100,"sourceType":"datasetVersion","datasetId":6729715}],"dockerImageVersionId":30918,"isInternetEnabled":true,"language":"python","sourceType":"notebook","isGpuEnabled":false}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"markdown","source":"# Common Task 1: Tokenize Squared Amplitudes","metadata":{}},{"cell_type":"code","source":"import numpy as np\nimport pandas as pd","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-04-02T05:50:21.562910Z","iopub.execute_input":"2025-04-02T05:50:21.563268Z","iopub.status.idle":"2025-04-02T05:50:21.979329Z","shell.execute_reply.started":"2025-04-02T05:50:21.563231Z","shell.execute_reply":"2025-04-02T05:50:21.978154Z"}},"outputs":[],"execution_count":1},{"cell_type":"markdown","source":"# Read Data","metadata":{}},{"cell_type":"code","source":"def read_txt(path):\n    with open(path,'r', encoding='utf-8') as f:\n        lines = f.read().split('\\n')\n    text_pairs = []\n    mx = 0 \n    mn = 100\n    x = []\n    for _line in lines:\n        arr = _line.split(':')\n        if len(arr) == 1:\n            continue\n        text_pairs.append({'Event Type': arr[0], 'Feynman Diagram': arr[1], \\\n                           'Amplitude': arr[-2], 'Squared Amplitude': arr[-1] \\\n                          })\n    return text_pairs","metadata":{"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","trusted":true,"execution":{"iopub.status.busy":"2025-04-02T05:50:22.433308Z","iopub.execute_input":"2025-04-02T05:50:22.433848Z","iopub.status.idle":"2025-04-02T05:50:22.440901Z","shell.execute_reply.started":"2025-04-02T05:50:22.433814Z","shell.execute_reply":"2025-04-02T05:50:22.439744Z"}},"outputs":[],"execution_count":2},{"cell_type":"code","source":"dir_path = '/kaggle/input/squared-amplitudes-test-data/SYMBA - Test Data/QED-2-to-2-diag-TreeLevel-'\nfinal_pairs = []\n\nfor i in range(10):\n    path = dir_path + f'{i}.txt'\n    final_pairs.extend(read_txt(path))\nprint(f'Length of dataset: {len(final_pairs)}')","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-04-02T05:50:25.698102Z","iopub.execute_input":"2025-04-02T05:50:25.698462Z","iopub.status.idle":"2025-04-02T05:50:25.979587Z","shell.execute_reply.started":"2025-04-02T05:50:25.698435Z","shell.execute_reply":"2025-04-02T05:50:25.978735Z"}},"outputs":[{"name":"stdout","text":"Length of dataset: 15552\n","output_type":"stream"}],"execution_count":3},{"cell_type":"code","source":"cols = ['Event Type', 'Feynman Diagram', 'Amplitude', 'Squared Amplitude']\ndtypes = { key: 'string' for key in cols}\ndf = pd.DataFrame(final_pairs, columns=cols)\ndf = df.astype(dtypes)","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-04-02T05:50:28.772582Z","iopub.execute_input":"2025-04-02T05:50:28.772937Z","iopub.status.idle":"2025-04-02T05:50:28.801711Z","shell.execute_reply.started":"2025-04-02T05:50:28.772913Z","shell.execute_reply":"2025-04-02T05:50:28.800509Z"}},"outputs":[],"execution_count":4},{"cell_type":"code","source":"df.head(3)","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-04-02T05:50:29.021593Z","iopub.execute_input":"2025-04-02T05:50:29.021944Z","iopub.status.idle":"2025-04-02T05:50:29.047139Z","shell.execute_reply.started":"2025-04-02T05:50:29.021917Z","shell.execute_reply":"2025-04-02T05:50:29.046042Z"}},"outputs":[{"execution_count":5,"output_type":"execute_result","data":{"text/plain":"    Event Type                                    Feynman Diagram  \\\n0  Interaction    e_gam_239(X)^(*)  e_del_219(X)^(*)  to  e_ep...   \n1  Interaction    e_gam_239(X)^(*)  e_del_219(X)^(*)  to  e_ep...   \n2  Interaction    e_gam_239(X)^(*)  e_del_219(X)^(*)  to  e_ep...   \n\n                                           Amplitude  \\\n0   -1/2*i*e^2*gamma_{+%\\sigma_165,%gam_145,%gam_...   \n1   1/2*i*e^2*gamma_{+%\\sigma_172,%gam_162,%del_1...   \n2   -1/2*i*e^2*gamma_{+%\\sigma_293,%gam_358,%gam_...   \n\n                                   Squared Amplitude  \n0   2*e^4*(m_e^4 + -1/2*m_e^2*s_13 + 1/2*s_14*s_2...  \n1   2*e^4*(m_e^4 + -1/2*m_e^2*s_14 + -1/2*m_e^2*s...  \n2   2*e^4*(m_e^4 + -1/2*m_e^2*s_13 + 1/2*s_14*s_2...  ","text/html":"<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>Event Type</th>\n      <th>Feynman Diagram</th>\n      <th>Amplitude</th>\n      <th>Squared Amplitude</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>0</th>\n      <td>Interaction</td>\n      <td>e_gam_239(X)^(*)  e_del_219(X)^(*)  to  e_ep...</td>\n      <td>-1/2*i*e^2*gamma_{+%\\sigma_165,%gam_145,%gam_...</td>\n      <td>2*e^4*(m_e^4 + -1/2*m_e^2*s_13 + 1/2*s_14*s_2...</td>\n    </tr>\n    <tr>\n      <th>1</th>\n      <td>Interaction</td>\n      <td>e_gam_239(X)^(*)  e_del_219(X)^(*)  to  e_ep...</td>\n      <td>1/2*i*e^2*gamma_{+%\\sigma_172,%gam_162,%del_1...</td>\n      <td>2*e^4*(m_e^4 + -1/2*m_e^2*s_14 + -1/2*m_e^2*s...</td>\n    </tr>\n    <tr>\n      <th>2</th>\n      <td>Interaction</td>\n      <td>e_gam_239(X)^(*)  e_del_219(X)^(*)  to  e_ep...</td>\n      <td>-1/2*i*e^2*gamma_{+%\\sigma_293,%gam_358,%gam_...</td>\n      <td>2*e^4*(m_e^4 + -1/2*m_e^2*s_13 + 1/2*s_14*s_2...</td>\n    </tr>\n  </tbody>\n</table>\n</div>"},"metadata":{}}],"execution_count":5},{"cell_type":"code","source":"df.iloc[0]['Amplitude']","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-04-02T05:50:33.132003Z","iopub.execute_input":"2025-04-02T05:50:33.132389Z","iopub.status.idle":"2025-04-02T05:50:33.138682Z","shell.execute_reply.started":"2025-04-02T05:50:33.132357Z","shell.execute_reply":"2025-04-02T05:50:33.137532Z"}},"outputs":[{"execution_count":6,"output_type":"execute_result","data":{"text/plain":"' -1/2*i*e^2*gamma_{+%\\\\sigma_165,%gam_145,%gam_146}*gamma_{%\\\\sigma_165,%gam_147,%del_137}*e_{i_3,%gam_146}(p_1)_u*e_{k_3,%del_137}(p_2)_u*e_{l_3,%gam_145}(p_3)_u^(*)*e_{i_5,%gam_147}(p_4)_u^(*)/(m_e^2 + -s_13 + 1/2*reg_prop) '"},"metadata":{}}],"execution_count":6},{"cell_type":"code","source":"df.iloc[0]['Squared Amplitude']","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-04-02T05:50:33.371323Z","iopub.execute_input":"2025-04-02T05:50:33.371667Z","iopub.status.idle":"2025-04-02T05:50:33.377749Z","shell.execute_reply.started":"2025-04-02T05:50:33.371614Z","shell.execute_reply":"2025-04-02T05:50:33.376894Z"}},"outputs":[{"execution_count":7,"output_type":"execute_result","data":{"text/plain":"' 2*e^4*(m_e^4 + -1/2*m_e^2*s_13 + 1/2*s_14*s_23 + -1/2*m_e^2*s_24 + 1/2*s_12*s_34)*(m_e^2 + -s_13 + 1/2*reg_prop)^(-2)'"},"metadata":{}}],"execution_count":7},{"cell_type":"markdown","source":"# Train-Test split","metadata":{}},{"cell_type":"code","source":"from sklearn.model_selection import train_test_split\n\ntrain_df, temp_df = train_test_split(df, test_size=0.2, random_state=42, shuffle=True)\nval_df, test_df = train_test_split(temp_df, test_size=0.5, random_state=42, shuffle=True)\n\nprint(f\"Train size: {len(train_df)}, Validation size: {len(val_df)}, Test size: {len(test_df)}\")\n\ntrain_df.to_csv('train.csv')\nval_df.to_csv('val.csv')\ntest_df.to_csv('test.csv')","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-04-02T05:50:35.653032Z","iopub.execute_input":"2025-04-02T05:50:35.653379Z","iopub.status.idle":"2025-04-02T05:50:36.705356Z","shell.execute_reply.started":"2025-04-02T05:50:35.653351Z","shell.execute_reply":"2025-04-02T05:50:36.704385Z"}},"outputs":[{"name":"stdout","text":"Train size: 12441, Validation size: 1555, Test size: 1556\n","output_type":"stream"}],"execution_count":8},{"cell_type":"markdown","source":"# Vocab from torchtext","metadata":{}},{"cell_type":"markdown","source":"As torchtext got deprecated, I have built vocab class from legacy source code. As this would be a simple and effective addition, compared to custom implementation.","metadata":{}},{"cell_type":"code","source":"import torch\nimport logging\nimport os\nimport zipfile\nimport gzip\nfrom urllib.request import urlretrieve\nfrom tqdm import tqdm\nimport tarfile\nfrom functools import partial\n\nlogger = logging.getLogger(__name__)\n\n\ndef _infer_shape(f):\n    num_lines, vector_dim = 0, None\n    for line in f:\n        if vector_dim is None:\n            row = line.rstrip().split(b\" \")\n            vector = row[1:]\n            # Assuming word, [vector] format\n            if len(vector) > 2:\n                # The header present in some (w2v) formats contains two elements.\n                vector_dim = len(vector)\n                num_lines += 1  # First element read\n        else:\n            num_lines += 1\n    f.seek(0)\n    return num_lines, vector_dim\n\n\ndef reporthook(t):\n    \"\"\"\n    https://github.com/tqdm/tqdm.\n    \"\"\"\n    last_b = [0]\n\n    def inner(b=1, bsize=1, tsize=None):\n        \"\"\"\n        b: int, optional\n        Number of blocks just transferred [default: 1].\n        bsize: int, optional\n        Size of each block (in tqdm units) [default: 1].\n        tsize: int, optional\n        Total size (in tqdm units). If [default: None] remains unchanged.\n        \"\"\"\n        if tsize is not None:\n            t.total = tsize\n        t.update((b - last_b[0]) * bsize)\n        last_b[0] = b\n\n    return inner","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-04-02T05:52:53.971600Z","iopub.execute_input":"2025-04-02T05:52:53.972010Z","iopub.status.idle":"2025-04-02T05:52:58.260225Z","shell.execute_reply.started":"2025-04-02T05:52:53.971977Z","shell.execute_reply":"2025-04-02T05:52:58.258840Z"}},"outputs":[],"execution_count":20},{"cell_type":"code","source":"class Vectors(object):\n\n    def __init__(self, name, cache=None,\n                 url=None, unk_init=None, max_vectors=None):\n        \"\"\"\n        Args:\n\n            name: name of the file that contains the vectors\n            cache: directory for cached vectors\n            url: url for download if vectors not found in cache\n            unk_init (callback): by default, initialize out-of-vocabulary word vectors\n                to zero vectors; can be any function that takes in a Tensor and returns a Tensor of the same size\n            max_vectors (int): this can be used to limit the number of\n                pre-trained vectors loaded.\n                Most pre-trained vector sets are sorted\n                in the descending order of word frequency.\n                Thus, in situations where the entire set doesn't fit in memory,\n                or is not needed for another reason, passing `max_vectors`\n                can limit the size of the loaded set.\n        \"\"\"\n\n        cache = '.vector_cache' if cache is None else cache\n        self.itos = None\n        self.stoi = None\n        self.vectors = None\n        self.dim = None\n        self.unk_init = torch.Tensor.zero_ if unk_init is None else unk_init\n        self.cache(name, cache, url=url, max_vectors=max_vectors)\n\n    def __getitem__(self, token):\n        if token in self.stoi:\n            return self.vectors[self.stoi[token]]\n        else:\n            return self.unk_init(torch.Tensor(self.dim))\n\n    def cache(self, name, cache, url=None, max_vectors=None):\n        import ssl\n        ssl._create_default_https_context = ssl._create_unverified_context\n        if os.path.isfile(name):\n            path = name\n            if max_vectors:\n                file_suffix = '_{}.pt'.format(max_vectors)\n            else:\n                file_suffix = '.pt'\n            path_pt = os.path.join(cache, os.path.basename(name)) + file_suffix\n        else:\n            path = os.path.join(cache, name)\n            if max_vectors:\n                file_suffix = '_{}.pt'.format(max_vectors)\n            else:\n                file_suffix = '.pt'\n            path_pt = path + file_suffix\n\n        if not os.path.isfile(path_pt):\n            if not os.path.isfile(path) and url:\n                logger.info('Downloading vectors from {}'.format(url))\n                if not os.path.exists(cache):\n                    os.makedirs(cache)\n                dest = os.path.join(cache, os.path.basename(url))\n                if not os.path.isfile(dest):\n                    with tqdm(unit='B', unit_scale=True, miniters=1, desc=dest) as t:\n                        try:\n                            urlretrieve(url, dest, reporthook=reporthook(t))\n                        except KeyboardInterrupt as e:  # remove the partial zip file\n                            os.remove(dest)\n                            raise e\n                logger.info('Extracting vectors into {}'.format(cache))\n                ext = os.path.splitext(dest)[1][1:]\n                if ext == 'zip':\n                    with zipfile.ZipFile(dest, \"r\") as zf:\n                        zf.extractall(cache)\n                elif ext == 'gz':\n                    if dest.endswith('.tar.gz'):\n                        with tarfile.open(dest, 'r:gz') as tar:\n                            tar.extractall(path=cache)\n            if not os.path.isfile(path):\n                raise RuntimeError('no vectors found at {}'.format(path))\n\n            logger.info(\"Loading vectors from {}\".format(path))\n            ext = os.path.splitext(path)[1][1:]\n            if ext == 'gz':\n                open_file = gzip.open\n            else:\n                open_file = open\n\n            vectors_loaded = 0\n            with open_file(path, 'rb') as f:\n                num_lines, dim = _infer_shape(f)\n                if not max_vectors or max_vectors > num_lines:\n                    max_vectors = num_lines\n\n                itos, vectors, dim = [], torch.zeros((max_vectors, dim)), None\n\n                for line in tqdm(f, total=max_vectors):\n                    # Explicitly splitting on \" \" is important, so we don't\n                    # get rid of Unicode non-breaking spaces in the vectors.\n                    entries = line.rstrip().split(b\" \")\n\n                    word, entries = entries[0], entries[1:]\n                    if dim is None and len(entries) > 1:\n                        dim = len(entries)\n                    elif len(entries) == 1:\n                        logger.warning(\"Skipping token {} with 1-dimensional \"\n                                       \"vector {}; likely a header\".format(word, entries))\n                        continue\n                    elif dim != len(entries):\n                        raise RuntimeError(\n                            \"Vector for token {} has {} dimensions, but previously \"\n                            \"read vectors have {} dimensions. All vectors must have \"\n                            \"the same number of dimensions.\".format(word, len(entries),\n                                                                    dim))\n\n                    try:\n                        if isinstance(word, bytes):\n                            word = word.decode('utf-8')\n                    except UnicodeDecodeError:\n                        logger.info(\"Skipping non-UTF8 token {}\".format(repr(word)))\n                        continue\n\n                    vectors[vectors_loaded] = torch.tensor([float(x) for x in entries])\n                    vectors_loaded += 1\n                    itos.append(word)\n\n                    if vectors_loaded == max_vectors:\n                        break\n\n            self.itos = itos\n            self.stoi = {word: i for i, word in enumerate(itos)}\n            self.vectors = torch.Tensor(vectors).view(-1, dim)\n            self.dim = dim\n            logger.info('Saving vectors to {}'.format(path_pt))\n            if not os.path.exists(cache):\n                os.makedirs(cache)\n            torch.save((self.itos, self.stoi, self.vectors, self.dim), path_pt)\n        else:\n            logger.info('Loading vectors from {}'.format(path_pt))\n            self.itos, self.stoi, self.vectors, self.dim = torch.load(path_pt)\n\n    def __len__(self):\n        return len(self.vectors)\n\n    def get_vecs_by_tokens(self, tokens, lower_case_backup=False):\n        \"\"\"Look up embedding vectors of tokens.\n\n        Args:\n            tokens: a token or a list of tokens. if `tokens` is a string,\n                returns a 1-D tensor of shape `self.dim`; if `tokens` is a\n                list of strings, returns a 2-D tensor of shape=(len(tokens),\n                self.dim).\n            lower_case_backup : Whether to look up the token in the lower case.\n                If False, each token in the original case will be looked up;\n                if True, each token in the original case will be looked up first,\n                if not found in the keys of the property `stoi`, the token in the\n                lower case will be looked up. Default: False.\n\n        Examples:\n            >>> examples = ['chip', 'baby', 'Beautiful']\n            >>> vec = text.vocab.GloVe(name='6B', dim=50)\n            >>> ret = vec.get_vecs_by_tokens(tokens, lower_case_backup=True)\n        \"\"\"\n        to_reduce = False\n\n        if not isinstance(tokens, list):\n            tokens = [tokens]\n            to_reduce = True\n\n        if not lower_case_backup:\n            indices = [self[token] for token in tokens]\n        else:\n            indices = [self[token] if token in self.stoi\n                       else self[token.lower()]\n                       for token in tokens]\n\n        vecs = torch.stack(indices)\n        return vecs[0] if to_reduce else vecs\n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-04-02T05:52:58.262286Z","iopub.execute_input":"2025-04-02T05:52:58.263147Z","iopub.status.idle":"2025-04-02T05:52:58.285038Z","shell.execute_reply.started":"2025-04-02T05:52:58.263108Z","shell.execute_reply":"2025-04-02T05:52:58.283804Z"}},"outputs":[],"execution_count":21},{"cell_type":"code","source":"class GloVe(Vectors):\n    url = {\n        '42B': 'http://nlp.stanford.edu/data/glove.42B.300d.zip',\n        '840B': 'http://nlp.stanford.edu/data/glove.840B.300d.zip',\n        'twitter.27B': 'http://nlp.stanford.edu/data/glove.twitter.27B.zip',\n        '6B': 'http://nlp.stanford.edu/data/glove.6B.zip',\n    }\n\n    def __init__(self, name='840B', dim=300, **kwargs):\n        url = self.url[name]\n        name = 'glove.{}.{}d.txt'.format(name, str(dim))\n        super(GloVe, self).__init__(name, url=url, **kwargs)\n\n\nclass FastText(Vectors):\n\n    url_base = 'https://dl.fbaipublicfiles.com/fasttext/vectors-wiki/wiki.{}.vec'\n\n    def __init__(self, language=\"en\", **kwargs):\n        url = self.url_base.format(language)\n        name = os.path.basename(url)\n        super(FastText, self).__init__(name, url=url, **kwargs)\n\n\nclass CharNGram(Vectors):\n\n    name = 'charNgram.txt'\n    url = ('http://www.logos.t.u-tokyo.ac.jp/~hassy/publications/arxiv2016jmt/'\n           'jmt_pre-trained_embeddings.tar.gz')\n\n    def __init__(self, **kwargs):\n        super(CharNGram, self).__init__(self.name, url=self.url, **kwargs)\n\n    def __getitem__(self, token):\n        vector = torch.Tensor(1, self.dim).zero_()\n        if token == \"<unk>\":\n            return self.unk_init(vector)\n        chars = ['#BEGIN#'] + list(token) + ['#END#']\n        num_vectors = 0\n        for n in [2, 3, 4]:\n            end = len(chars) - n + 1\n            grams = [chars[i:(i + n)] for i in range(end)]\n            for gram in grams:\n                gram_key = '{}gram-{}'.format(n, ''.join(gram))\n                if gram_key in self.stoi:\n                    vector += self.vectors[self.stoi[gram_key]]\n                    num_vectors += 1\n        if num_vectors > 0:\n            vector /= num_vectors\n        else:\n            vector = self.unk_init(vector)\n        return vector\n\n\npretrained_aliases = {\n    \"charngram.100d\": partial(CharNGram),\n    \"fasttext.en.300d\": partial(FastText, language=\"en\"),\n    \"fasttext.simple.300d\": partial(FastText, language=\"simple\"),\n    \"glove.42B.300d\": partial(GloVe, name=\"42B\", dim=\"300\"),\n    \"glove.840B.300d\": partial(GloVe, name=\"840B\", dim=\"300\"),\n    \"glove.twitter.27B.25d\": partial(GloVe, name=\"twitter.27B\", dim=\"25\"),\n    \"glove.twitter.27B.50d\": partial(GloVe, name=\"twitter.27B\", dim=\"50\"),\n    \"glove.twitter.27B.100d\": partial(GloVe, name=\"twitter.27B\", dim=\"100\"),\n    \"glove.twitter.27B.200d\": partial(GloVe, name=\"twitter.27B\", dim=\"200\"),\n    \"glove.6B.50d\": partial(GloVe, name=\"6B\", dim=\"50\"),\n    \"glove.6B.100d\": partial(GloVe, name=\"6B\", dim=\"100\"),\n    \"glove.6B.200d\": partial(GloVe, name=\"6B\", dim=\"200\"),\n    \"glove.6B.300d\": partial(GloVe, name=\"6B\", dim=\"300\")\n}\n\"\"\"Mapping from string name to factory function\"\"\"\n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-04-02T05:52:58.287172Z","iopub.execute_input":"2025-04-02T05:52:58.287600Z","iopub.status.idle":"2025-04-02T05:52:58.317162Z","shell.execute_reply.started":"2025-04-02T05:52:58.287569Z","shell.execute_reply":"2025-04-02T05:52:58.315990Z"}},"outputs":[{"execution_count":22,"output_type":"execute_result","data":{"text/plain":"'Mapping from string name to factory function'"},"metadata":{}}],"execution_count":22},{"cell_type":"code","source":"from collections import defaultdict\nimport logging\nimport torch\nfrom tqdm import tqdm\nfrom collections import Counter\n# from torchtext.vocab import (\n#     pretrained_aliases,  # not in legacy\n#     Vectors,  # not in legacy\n# )\nfrom typing import List\nlogger = logging.getLogger(__name__)\n\n\nclass Vocab(object):\n    \"\"\"Defines a vocabulary object that will be used to numericalize a field.\n\n    Attributes:\n        freqs: A collections.Counter object holding the frequencies of tokens\n            in the data used to build the Vocab.\n        stoi: A collections.defaultdict instance mapping token strings to\n            numerical identifiers.\n        itos: A list of token strings indexed by their numerical identifiers.\n    \"\"\"\n\n    # TODO (@mttk): Populate classs with default values of special symbols\n    UNK = '<unk>'\n\n    def __init__(self, counter, max_size=None, min_freq=1, specials=('<unk>', '<pad>'),\n                 vectors=None, unk_init=None, vectors_cache=None, specials_first=True):\n        \"\"\"Create a Vocab object from a collections.Counter.\n\n        Args:\n            counter: collections.Counter object holding the frequencies of\n                each value found in the data.\n            max_size: The maximum size of the vocabulary, or None for no\n                maximum. Default: None.\n            min_freq: The minimum frequency needed to include a token in the\n                vocabulary. Values less than 1 will be set to 1. Default: 1.\n            specials: The list of special tokens (e.g., padding or eos) that\n                will be prepended to the vocabulary. Default: ['<unk'>, '<pad>']\n            vectors: One of either the available pretrained vectors\n                or custom pretrained vectors (see Vocab.load_vectors);\n                or a list of aforementioned vectors\n            unk_init (callback): by default, initialize out-of-vocabulary word vectors\n                to zero vectors; can be any function that takes in a Tensor and\n                returns a Tensor of the same size. Default: 'torch.zeros'\n            vectors_cache: directory for cached vectors. Default: '.vector_cache'\n            specials_first: Whether to add special tokens into the vocabulary at first.\n                If it is False, they are added into the vocabulary at last.\n                Default: True.\n        \"\"\"\n        self.freqs = counter\n        counter = counter.copy()\n        min_freq = max(min_freq, 1)\n\n        self.itos = list()\n        self.unk_index = None\n        if specials_first:\n            self.itos = list(specials)\n            # only extend max size if specials are prepended\n            max_size = None if max_size is None else max_size + len(specials)\n\n        # frequencies of special tokens are not counted when building vocabulary\n        # in frequency order\n        for tok in specials:\n            if tok in counter:\n                del counter[tok]\n\n        # sort by frequency, then alphabetically\n        words_and_frequencies = sorted(counter.items(), key=lambda tup: tup[0])\n        words_and_frequencies.sort(key=lambda tup: tup[1], reverse=True)\n\n        for word, freq in words_and_frequencies:\n            if freq < min_freq or len(self.itos) == max_size:\n                break\n            self.itos.append(word)\n\n        if Vocab.UNK in specials:  # hard-coded for now\n            unk_index = specials.index(Vocab.UNK)  # position in list\n            # account for ordering of specials, set variable\n            self.unk_index = unk_index if specials_first else len(self.itos) + unk_index\n            self.stoi = defaultdict(self._default_unk_index)\n        else:\n            self.stoi = defaultdict()\n\n        if not specials_first:\n            self.itos.extend(list(specials))\n\n        # stoi is simply a reverse dict for itos\n        self.stoi.update({tok: i for i, tok in enumerate(self.itos)})\n\n        self.vectors = None\n        if vectors is not None:\n            self.load_vectors(vectors, unk_init=unk_init, cache=vectors_cache)\n        else:\n            assert unk_init is None and vectors_cache is None\n\n    def forward(self, tokens: List[str]) -> List[int]:\n        return self.lookup_indices(tokens)\n\n    def set_default_index(self, idx):\n        self.unk_index = idx\n        \n    def _default_unk_index(self):\n        return self.unk_index\n\n    def __getitem__(self, token):\n        return self.stoi.get(token, self.stoi.get(Vocab.UNK))\n\n    def __getstate__(self):\n        # avoid picking defaultdict\n        attrs = dict(self.__dict__)\n        # cast to regular dict\n        attrs['stoi'] = dict(self.stoi)\n        return attrs\n\n    def __setstate__(self, state):\n        if state.get(\"unk_index\", None) is None:\n            stoi = defaultdict()\n        else:\n            stoi = defaultdict(self._default_unk_index)\n        stoi.update(state['stoi'])\n        state['stoi'] = stoi\n        self.__dict__.update(state)\n\n    def __eq__(self, other):\n        if self.freqs != other.freqs:\n            return False\n        if self.stoi != other.stoi:\n            return False\n        if self.itos != other.itos:\n            return False\n        if self.vectors != other.vectors:\n            return False\n        return True\n\n    def __len__(self):\n        return len(self.itos)\n\n    def lookup_indices(self, tokens):\n        indices = [self.__getitem__(token) for token in tokens]\n        return indices\n\n    def extend(self, v, sort=False):\n        words = sorted(v.itos) if sort else v.itos\n        for w in words:\n            if w not in self.stoi:\n                self.itos.append(w)\n                self.stoi[w] = len(self.itos) - 1\n\n    def load_vectors(self, vectors, **kwargs):\n        \"\"\"\n        Args:\n            vectors: one of or a list containing instantiations of the\n                GloVe, CharNGram, or Vectors classes. Alternatively, one\n                of or a list of available pretrained vectors:\n\n                charngram.100d\n                fasttext.en.300d\n                fasttext.simple.300d\n                glove.42B.300d\n                glove.840B.300d\n                glove.twitter.27B.25d\n                glove.twitter.27B.50d\n                glove.twitter.27B.100d\n                glove.twitter.27B.200d\n                glove.6B.50d\n                glove.6B.100d\n                glove.6B.200d\n                glove.6B.300d\n\n            Remaining keyword arguments: Passed to the constructor of Vectors classes.\n        \"\"\"\n        if not isinstance(vectors, list):\n            vectors = [vectors]\n        for idx, vector in enumerate(vectors):\n            if isinstance(vector, str):\n                # Convert the string pretrained vector identifier\n                # to a Vectors object\n                if vector not in pretrained_aliases:\n                    raise ValueError(\"Got string input vector {}, but allowed pretrained vectors are {}\".format(vector, list(pretrained_aliases.keys())))\n                vectors[idx] = pretrained_aliases[vector](**kwargs)\n            elif not isinstance(vector, Vectors):\n                raise ValueError( \"Got input vectors of type {}, expected str or Vectors object\".format(type(vector)))\n        tot_dim = sum(v.dim for v in vectors)\n        self.vectors = torch.Tensor(len(self), tot_dim)\n        for i, token in enumerate(self.itos):\n            start_dim = 0\n            for v in vectors:\n                end_dim = start_dim + v.dim\n                self.vectors[i][start_dim:end_dim] = v[token.strip()]\n                start_dim = end_dim\n            assert(start_dim == tot_dim)\n\n    def set_vectors(self, stoi, vectors, dim, unk_init=torch.Tensor.zero_):\n        \"\"\"\n        Set the vectors for the Vocab instance from a collection of Tensors.\n\n        Args:\n            stoi: A dictionary of string to the index of the associated vector\n                in the `vectors` input argument.\n            vectors: An indexed iterable (or other structure supporting __getitem__) that\n                given an input index, returns a FloatTensor representing the vector\n                for the token associated with the index. For example,\n                vector[stoi[\"string\"]] should return the vector for \"string\".\n            dim: The dimensionality of the vectors.\n            unk_init (callback): by default, initialize out-of-vocabulary word vectors\n                to zero vectors; can be any function that takes in a Tensor and\n                returns a Tensor of the same size. Default: 'torch.zeros'\n        \"\"\"\n        self.vectors = torch.Tensor(len(self), dim)\n        for i, token in enumerate(self.itos):\n            wv_index = stoi.get(token, None)\n            if wv_index is not None:\n                self.vectors[i] = vectors[wv_index]\n            else:\n                self.vectors[i] = unk_init(self.vectors[i])\n\n\nclass SubwordVocab(Vocab):\n\n    def __init__(self, counter, max_size=None, specials=('<pad>'),\n                 vectors=None, unk_init=torch.Tensor.zero_):\n        \"\"\"Create a revtok subword vocabulary from a collections.Counter.\n\n        Args:\n            counter: collections.Counter object holding the frequencies of\n                each word found in the data.\n            max_size: The maximum size of the subword vocabulary, or None for no\n                maximum. Default: None.\n            specials: The list of special tokens (e.g., padding or eos) that\n                will be prepended to the vocabulary in addition to an <unk>\n                token.\n            vectors: One of either the available pretrained vectors\n                or custom pretrained vectors (see Vocab.load_vectors);\n                or a list of aforementioned vectors\n            unk_init (callback): by default, initialize out-of-vocabulary word vectors\n                to zero vectors; can be any function that takes in a Tensor and\n                returns a Tensor of the same size. Default: 'torch.zeros\n        \"\"\"\n        try:\n            import revtok\n        except ImportError:\n            print(\"Please install revtok.\")\n            raise\n\n        # Hardcode unk_index as subword_vocab has no specials_first argument\n        self.unk_index = (specials.index(SubwordVocab.UNK)\n                          if SubwordVocab.UNK in specials else None)\n\n        if self.unk_index is None:\n            self.stoi = defaultdict()\n        else:\n            self.stoi = defaultdict(self._default_unk_index)\n\n        self.stoi.update({tok: i for i, tok in enumerate(specials)})\n        self.itos = specials.copy()\n\n        self.segment = revtok.SubwordSegmenter(counter, max_size)\n\n        max_size = None if max_size is None else max_size + len(self.itos)\n\n        # sort by frequency/entropy, then alphabetically\n        toks = sorted(self.segment.vocab.items(), key=lambda tup: (len(tup[0]) != 1, -tup[1], tup[0]))\n\n        for tok, _ in toks:\n            if len(self.itos) == max_size:\n                break\n            self.itos.append(tok)\n            self.stoi[tok] = len(self.itos) - 1\n\n        if vectors is not None:\n            self.load_vectors(vectors, unk_init=unk_init)\n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-04-02T05:52:58.318237Z","iopub.execute_input":"2025-04-02T05:52:58.318554Z","iopub.status.idle":"2025-04-02T05:52:58.347256Z","shell.execute_reply.started":"2025-04-02T05:52:58.318514Z","shell.execute_reply":"2025-04-02T05:52:58.346065Z"}},"outputs":[],"execution_count":23},{"cell_type":"markdown","source":"# Tokenizer","metadata":{}},{"cell_type":"code","source":"from collections import Counter, OrderedDict\nfrom itertools import cycle\nimport re\nimport random\nfrom tqdm import tqdm\nimport warnings\n\nclass Tokenizer:\n    \"\"\"\n    Tokenizer for processing symbolic mathematical expressions.\n    \"\"\"\n    def __init__(self, df, index_token_pool_size, momentum_token_pool_size, special_symbols, UNK_IDX, to_replace):\n        self.amps = df.Amplitude.tolist()\n        self.sqamps = df['Squared Amplitude'].tolist()\n\n        # Generate token pools\n        self.tokens_pool = [f\"_{i}\" for i in range(index_token_pool_size)]\n        self.momentum_pool = [f\"MOMENTUM_{i}\" for i in range(momentum_token_pool_size)]\n        \n        # Regular expression patterns for token replacement\n        self.pattern_momentum = re.compile(r'\\b[p]_\\d{1,}\\b')\n        self.pattern_num_123 = re.compile(r'\\b(?![ps]_)\\w+_\\d{1,}\\b')\n        self.pattern_special = re.compile(r'\\b\\w+_+\\w+\\b\\\\')\n        self.pattern_prop = re.compile(r'Prop')\n        self.pattern_int = re.compile(r'int\\{')\n        self.pattern_operators = {\n            '+': re.compile(r'\\+'), '-': re.compile(r'-'), '*': re.compile(r'\\*'),\n            ',': re.compile(r','), '^': re.compile(r'\\^'), '%': re.compile(r'%'),\n            '}': re.compile(r'\\}'), '(': re.compile(r'\\('), ')': re.compile(r'\\)')\n        }\n        self.function_opening = re.compile(r'(\\w+_\\{)')\n        self.pattern_mass = re.compile(r'\\b\\w+_\\w\\b')\n        self.pattern_s = re.compile(r'\\b\\w+_\\d{2,}\\b')\n        self.pattern_reg_prop = re.compile(r'\\b\\w+_\\d{1}\\b')\n        self.pattern_antipart = re.compile(r'(\\w)_\\w+_\\d+\\(X\\)\\^\\(\\*\\)')\n        self.pattern_part = re.compile(r'(\\w)_\\w+_\\d+\\(X\\)')\n        self.pattern_index = re.compile(r'\\b\\w+_\\w+_\\d{2,}\\b')\n        \n        self.special_symbols = special_symbols\n        self.UNK_IDX = UNK_IDX\n        self.to_replace = to_replace\n\n    @staticmethod\n    def remove_whitespace(expression):\n        \"\"\"Remove all forms of whitespace from the expression.\"\"\"\n        return re.sub(r'\\s+', '', expression)\n\n    @staticmethod\n    def split_expression(expression):\n        \"\"\"Split the expression by space delimiter.\"\"\"\n        return re.split(r' ', expression)\n\n    def build_tgt_vocab(self):\n        \"\"\"Build vocabulary for target sequences.\"\"\"\n        counter = Counter()\n        for eqn in tqdm(self.sqamps, desc='Processing target vocab'):\n            counter.update(self.tgt_tokenize(eqn))\n        voc = Vocab(OrderedDict(counter), specials=self.special_symbols[:], specials_first=True)\n        voc.set_default_index(self.UNK_IDX)\n        return voc\n\n    def build_src_vocab(self, seed):\n        \"\"\"Build vocabulary for source sequences.\"\"\"\n        counter = Counter()\n        for diag in tqdm(self.amps, desc='Processing source vocab'):\n            counter.update(self.src_tokenize(diag, seed))\n        voc = Vocab(OrderedDict(counter), specials=self.special_symbols[:], specials_first=True)\n        voc.set_default_index(self.UNK_IDX)\n        return voc\n    \n    def src_replace(self, ampl, seed):\n        \"\"\"Replace indexed and momentum variables with tokenized equivalents.\"\"\"\n        ampl = self.remove_whitespace(ampl)\n        \n        random.seed(seed)\n        token_cycle = cycle(random.sample(self.tokens_pool, len(self.tokens_pool)))\n        momentum_cycle = cycle(random.sample(self.momentum_pool, len(self.momentum_pool)))\n        \n        # Replace momentum tokens\n        temp_ampl = ampl\n        momentum_mapping = {match: next(momentum_cycle) for match in set(self.pattern_momentum.findall(ampl))}\n        for key, value in momentum_mapping.items():\n            temp_ampl = temp_ampl.replace(key, value)\n\n\n        def replace_123_match(match):\n            word, num = match.group().rsplit('_', 1)\n            return f\"{word}_INDEX_{next(token_cycle)}\"\n        temp_ampl = re.sub(self.pattern_num_123,replace_123_match,ampl)\n        return temp_ampl\n    \n    def src_tokenize(self, ampl, seed):\n        \"\"\"Tokenize source expression, optionally applying replacements.\"\"\"\n        temp_ampl = self.src_replace(ampl, seed) if self.to_replace else ampl\n        temp_ampl = temp_ampl.replace('\\\\\\\\', '\\\\').replace('\\\\', ' \\\\ ').replace('%', '')\n        \n        for symbol, pattern in self.pattern_operators.items():\n            temp_ampl = pattern.sub(f' {symbol} ', temp_ampl)\n\n        temp_ampl = self.function_opening.sub(r'\\1 ', temp_ampl)\n        \n        temp_ampl = re.sub(r' {2,}', ' ', temp_ampl)\n        return [token for token in self.split_expression(temp_ampl) if token]\n\n    def tgt_tokenize(self, sqampl):\n        \"\"\"Tokenize target expression.\"\"\"\n        sqampl = self.remove_whitespace(sqampl)\n        temp_sqampl = sqampl\n        \n        for symbol, pattern in self.pattern_operators.items():\n            temp_sqampl = pattern.sub(f' {symbol} ', temp_sqampl)\n        \n        for pattern in [self.pattern_reg_prop, self.pattern_mass, self.pattern_s]:\n            temp_sqampl = pattern.sub(lambda match: f' {match.group(0)} ', temp_sqampl)\n        \n        temp_sqampl = re.sub(r' {2,}', ' ', temp_sqampl)\n        return [token for token in self.split_expression(temp_sqampl) if token]","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-04-02T05:52:02.311018Z","iopub.execute_input":"2025-04-02T05:52:02.311355Z","iopub.status.idle":"2025-04-02T05:52:02.336982Z","shell.execute_reply.started":"2025-04-02T05:52:02.311329Z","shell.execute_reply":"2025-04-02T05:52:02.335740Z"}},"outputs":[],"execution_count":9},{"cell_type":"code","source":"BOS_IDX, PAD_IDX, EOS_IDX, UNK_IDX, SEP_IDX = 0, 1, 2, 3, 4\nspecial_symbols = ['<S>', '<PAD>', '</S>', '<UNK>', '<SEP>']\ndummy_tokenizer = Tokenizer(train_df, 500, 500, special_symbols, UNK_IDX, False)","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-04-02T05:52:02.571809Z","iopub.execute_input":"2025-04-02T05:52:02.572237Z","iopub.status.idle":"2025-04-02T05:52:02.585313Z","shell.execute_reply.started":"2025-04-02T05:52:02.572202Z","shell.execute_reply":"2025-04-02T05:52:02.584133Z"}},"outputs":[],"execution_count":10},{"cell_type":"code","source":"def normalize_indices(tokenizer, expressions, index_token_pool_size=50, momentum_token_pool_size=50):\n    # Function to replace indices with a new set of tokens for each expression\n    def replace_indices(token_list, index_map):\n        new_index = (f\"{i}\" for i in range(index_token_pool_size))  # Local generator for new indices\n        new_tokens = []\n        for token in token_list:\n            if \"INDEX_\" in token:\n                if token not in index_map:\n                    try:\n                        index_map[token] = token.rsplit('_',1)[0] + next(new_index)\n                    except StopIteration:\n                        # Handle the case where no more indices are available\n                        raise ValueError(\"Ran out of unique indices, increase token_pool_size\")\n                new_tokens.append(index_map[token])\n            else:\n                new_tokens.append(token)\n        return new_tokens\n    def replace_momenta(token_list, index_map):\n        new_index = (f\"MOMENTUM_{i}\" for i in range(momentum_token_pool_size))  # Local generator for new indices\n        new_tokens = []\n        for token in token_list:\n            if \"MOMENTUM_\" in token:\n                if token not in index_map:\n                    try:\n                        index_map[token] = next(new_index)\n                    except StopIteration:\n                        # Handle the case where no more indices are available\n                        raise ValueError(\"Ran out of unique indices, increase momentum_token_pool_size\")\n                new_tokens.append(index_map[token])\n            else:\n                new_tokens.append(token)\n        return new_tokens\n\n\n    normalized_expressions = []\n    # Replace indices in each expression randomly\n    for expr in tqdm(expressions,desc=\"Normalizing..\"):\n        toks = tokenizer.src_tokenize(expr,42)\n        normalized_expressions.append(replace_momenta(replace_indices(toks, {}), {}))\n\n    return normalized_expressions","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-04-02T05:52:12.661938Z","iopub.execute_input":"2025-04-02T05:52:12.662315Z","iopub.status.idle":"2025-04-02T05:52:12.671024Z","shell.execute_reply.started":"2025-04-02T05:52:12.662281Z","shell.execute_reply":"2025-04-02T05:52:12.669726Z"}},"outputs":[],"execution_count":12},{"cell_type":"code","source":"def aug_data(df):\n    # Extract columns\n    amps = df['Amplitude']\n    sqamps = df['Squared Amplitude']\n\n    # Data augmentation\n    n_samples = 1 #args.n_samples\n    aug_amps = []\n\n    for amp in tqdm(amps, desc='processing'):\n        random_seed = [random.randint(1, 1000) for _ in range(n_samples)]\n        for seed in random_seed:\n            aug_amps.append(dummy_tokenizer.src_replace(amp, seed))\n    aug_sqamps = [sqamp for sqamp in sqamps for _ in range(n_samples)]\n\n    if True:\n        normal_amps = normalize_indices(dummy_tokenizer, aug_amps, 500, 500)\n        aug_amps = []\n        for amp in normal_amps:\n            aug_amps.append(\"\".join(amp))\n\n    # Create augmented DataFrame\n    df_aug = pd.DataFrame({\"Amplitude\": aug_amps, \"Squared Amplitude\": aug_sqamps})\n\n    return df_aug\n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-04-02T05:52:12.793044Z","iopub.execute_input":"2025-04-02T05:52:12.793390Z","iopub.status.idle":"2025-04-02T05:52:12.799863Z","shell.execute_reply.started":"2025-04-02T05:52:12.793360Z","shell.execute_reply":"2025-04-02T05:52:12.798740Z"}},"outputs":[],"execution_count":13},{"cell_type":"code","source":"train_df_aug = aug_data(train_df)\nval_df_aug = aug_data(val_df)\ntest_df_aug = aug_data(test_df)","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-04-02T05:52:15.121535Z","iopub.execute_input":"2025-04-02T05:52:15.121928Z","iopub.status.idle":"2025-04-02T05:52:28.292545Z","shell.execute_reply.started":"2025-04-02T05:52:15.121897Z","shell.execute_reply":"2025-04-02T05:52:28.291295Z"}},"outputs":[{"name":"stderr","text":"processing: 100%|██████████| 12441/12441 [00:07<00:00, 1591.52it/s]\nNormalizing..: 100%|██████████| 12441/12441 [00:02<00:00, 4683.62it/s]\nprocessing: 100%|██████████| 1555/1555 [00:00<00:00, 1604.38it/s]\nNormalizing..: 100%|██████████| 1555/1555 [00:00<00:00, 4932.39it/s]\nprocessing: 100%|██████████| 1556/1556 [00:00<00:00, 1596.57it/s]\nNormalizing..: 100%|██████████| 1556/1556 [00:00<00:00, 4776.66it/s]\n","output_type":"stream"}],"execution_count":14},{"cell_type":"code","source":"train_df_aug.to_csv('train.csv')\nval_df_aug.to_csv('valid.csv')\ntest_df_aug.to_csv('test.csv')","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-04-02T05:52:28.294170Z","iopub.execute_input":"2025-04-02T05:52:28.294571Z","iopub.status.idle":"2025-04-02T05:52:28.577665Z","shell.execute_reply.started":"2025-04-02T05:52:28.294531Z","shell.execute_reply":"2025-04-02T05:52:28.576845Z"}},"outputs":[],"execution_count":15},{"cell_type":"code","source":"len(pd.read_csv('train.csv'))","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-04-02T05:52:30.053687Z","iopub.execute_input":"2025-04-02T05:52:30.054065Z","iopub.status.idle":"2025-04-02T05:52:30.165258Z","shell.execute_reply.started":"2025-04-02T05:52:30.054028Z","shell.execute_reply":"2025-04-02T05:52:30.164251Z"}},"outputs":[{"execution_count":16,"output_type":"execute_result","data":{"text/plain":"12441"},"metadata":{}}],"execution_count":16},{"cell_type":"code","source":"# train_df_aug['Amplitude'][10]","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-04-01T17:24:27.155362Z","iopub.execute_input":"2025-04-01T17:24:27.155709Z","iopub.status.idle":"2025-04-01T17:24:27.160114Z","shell.execute_reply.started":"2025-04-01T17:24:27.155683Z","shell.execute_reply":"2025-04-01T17:24:27.159074Z"}},"outputs":[],"execution_count":25},{"cell_type":"code","source":"tokenizer = Tokenizer(train_df_aug, 500, 500, special_symbols, UNK_IDX, False)","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-04-02T05:52:33.962252Z","iopub.execute_input":"2025-04-02T05:52:33.962609Z","iopub.status.idle":"2025-04-02T05:52:33.969179Z","shell.execute_reply.started":"2025-04-02T05:52:33.962577Z","shell.execute_reply":"2025-04-02T05:52:33.968087Z"}},"outputs":[],"execution_count":17},{"cell_type":"code","source":"src_vocab = tokenizer.build_src_vocab(42)\ntgt_vocab = tokenizer.build_tgt_vocab()","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-04-02T05:53:10.221944Z","iopub.execute_input":"2025-04-02T05:53:10.222427Z","iopub.status.idle":"2025-04-02T05:53:13.909385Z","shell.execute_reply.started":"2025-04-02T05:53:10.222382Z","shell.execute_reply":"2025-04-02T05:53:13.908116Z"}},"outputs":[{"name":"stderr","text":"Processing source vocab: 100%|██████████| 12441/12441 [00:01<00:00, 6854.71it/s]\nProcessing target vocab: 100%|██████████| 12441/12441 [00:01<00:00, 6698.02it/s]\n","output_type":"stream"}],"execution_count":25},{"cell_type":"code","source":"print('Source vocab size: ',len(src_vocab), ' \\nTarget Vocab size:', len(tgt_vocab))","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-04-02T06:07:28.741249Z","iopub.execute_input":"2025-04-02T06:07:28.741765Z","iopub.status.idle":"2025-04-02T06:07:28.748521Z","shell.execute_reply.started":"2025-04-02T06:07:28.741722Z","shell.execute_reply":"2025-04-02T06:07:28.747093Z"}},"outputs":[{"name":"stdout","text":"Source vocab size:  459  \nTarget Vocab size: 59\n","output_type":"stream"}],"execution_count":38},{"cell_type":"code","source":"from tqdm.auto import tqdm\naln = []\nsln = []\nfor idx,row in tqdm(train_df_aug.iterrows(),total=len(train_df_aug)):\n    aln.append(len(tokenizer.src_tokenize(row['Amplitude'],seed=42)))\n    sln.append(len(tokenizer.tgt_tokenize(row['Squared Amplitude'])))","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-04-02T05:54:31.471205Z","iopub.execute_input":"2025-04-02T05:54:31.471607Z","iopub.status.idle":"2025-04-02T05:54:36.484645Z","shell.execute_reply.started":"2025-04-02T05:54:31.471578Z","shell.execute_reply":"2025-04-02T05:54:36.483552Z"}},"outputs":[{"output_type":"display_data","data":{"text/plain":"  0%|          | 0/12441 [00:00<?, ?it/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"0d185025c7484bcb98d26c7dda1c28ad"}},"metadata":{}}],"execution_count":29},{"cell_type":"code","source":"!pip install -q matplotlib==3.8.0","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-04-02T05:54:40.331334Z","iopub.execute_input":"2025-04-02T05:54:40.331728Z","iopub.status.idle":"2025-04-02T05:55:05.618478Z","shell.execute_reply.started":"2025-04-02T05:54:40.331699Z","shell.execute_reply":"2025-04-02T05:55:05.617151Z"}},"outputs":[{"name":"stdout","text":"\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m11.6/11.6 MB\u001b[0m \u001b[31m74.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m:00:01\u001b[0m0:01\u001b[0m\n\u001b[?25h\u001b[31mERROR: pip's dependency resolver does not currently take into account all the packages that are installed. This behaviour is the source of the following dependency conflicts.\nmlxtend 0.23.3 requires scikit-learn>=1.3.1, but you have scikit-learn 1.2.2 which is incompatible.\u001b[0m\u001b[31m\n\u001b[0m","output_type":"stream"}],"execution_count":30},{"cell_type":"code","source":"import numpy as np\nimport matplotlib.pyplot as plt\n\nahist, abase = np.histogram(aln, bins=30)\nacum = np.cumsum(ahist)\nplt.plot(abase[:-1], acum/len(aln), c='blue', label='source')\nshist, sbase = np.histogram(sln, bins=30)\nscum = np.cumsum(shist)\nplt.plot(sbase[:-1], scum/len(sln), c='red', label='target')\nplt.legend()","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-04-02T05:55:05.620727Z","iopub.execute_input":"2025-04-02T05:55:05.621227Z","iopub.status.idle":"2025-04-02T05:55:05.941686Z","shell.execute_reply.started":"2025-04-02T05:55:05.621179Z","shell.execute_reply":"2025-04-02T05:55:05.940551Z"}},"outputs":[{"execution_count":31,"output_type":"execute_result","data":{"text/plain":"<matplotlib.legend.Legend at 0x7fadc92e3f10>"},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"<Figure size 640x480 with 1 Axes>","image/png":"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\n"},"metadata":{}}],"execution_count":31},{"cell_type":"code","source":"print(tokenizer.src_tokenize(train_df_aug['Amplitude'][10],seed=42))","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-04-02T06:04:20.513683Z","iopub.execute_input":"2025-04-02T06:04:20.514073Z","iopub.status.idle":"2025-04-02T06:04:20.519846Z","shell.execute_reply.started":"2025-04-02T06:04:20.514042Z","shell.execute_reply":"2025-04-02T06:04:20.518763Z"}},"outputs":[{"name":"stdout","text":"['-', '1/6', '*', 'i', '*', 'e', '^', '2', '*', 'gamma_{', '+', '\\\\', 'tau_INDEX_0', ',', 'eta_INDEX_1', ',', 'alpha_INDEX_2', '}', '*', 'gamma_{', '\\\\', 'tau_INDEX_3', ',', 'gam_INDEX_4', ',', 'del_INDEX_5', '}', '*', 'b_{', 'j_INDEX_6', ',', 'gam_INDEX_7', '}', '(', 'p_4', ')', '_u', '^', '(', '*', ')', '*', 'b_{', 'i_INDEX_8', ',', 'del_INDEX_9', '}', '(', 'p_3', ')', '_v', '*', 'mu_{', 'k_INDEX_10', ',', 'alpha_INDEX_11', '}', '(', 'p_1', ')', '_u', '*', 'mu_{', 'l_INDEX_12', ',', 'eta_INDEX_13', '}', '(', 'p_2', ')', '_v', '^', '(', '*', ')', '/', '(', 'm_mu', '^', '2', '+', 's_12', '+', '1/2', '*', 'reg_prop', ')']\n","output_type":"stream"}],"execution_count":35},{"cell_type":"code","source":"","metadata":{"trusted":true},"outputs":[],"execution_count":null}]}